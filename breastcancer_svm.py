# -*- coding: utf-8 -*-
"""BreastCancer_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1loGMKy78ANQPbhPagzV9feFqT2TGinD2

The dataset is read from "Breastcancer.csv" file, then the features with high multicolinearitty of threshold 0.81 above is dropped.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn import svm
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report


#Reading the dataset from data.csv file
ip = pd.read_csv("Breastcancer.csv")


ip.head()

ip.tail()

ip.info()

ip.isna().sum() 

len(ip.index), len(ip.columns)

#Dropping the columns with all missing value
ip = ip.dropna(axis=1)

#Shape of the data
ip.shape

ip.describe()
ip.describe(include="O")

#Counting the number of class labels Malignant as M and Benign as B
ip.diagnosis.value_counts()

#Visualization of class labels count
sns.countplot(ip['diagnosis'], palette='husl')


labelencoder_Y = LabelEncoder()
ip.iloc[:,1]=labelencoder_Y.fit_transform(ip.iloc[:,1].values)

ip.head()

#Dropping id column as it is not required
ip.drop('id',axis=1,inplace=True)

ip.head()

#finding correleation between the attributes
ip.corr()
plt.figure(figsize=(20,20))


#generating scatter plot matrix with the mean columns
col = ['diagnosis',
        'radius_mean', 
        'texture_mean', 
        'perimeter_mean', 
        'area_mean', 
        'smoothness_mean', 
        'compactness_mean', 
        'concavity_mean',
        'concave points_mean', 
        'symmetry_mean', 
        'fractal_dimension_mean']

sns.pairplot(data=ip[col], hue='diagnosis', palette='rocket')


#Almost perfectly linear patterns between the radius, perimeter and area attributes are hinting at the presence of multicollinearity between these variables. (they are highly linearly related) Another set of variables that possibly imply multicollinearity are the concavity, concave_points and compactness.

# Heatmap to visualize the multicollinearity
corr = ip.corr().round(2)
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True
cmap = sns.diverging_palette(220, 10, as_cmap=True)
f, ax = plt.subplots(figsize=(20, 20))
sns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5}, annot=True)
plt.tight_layout()

#Removing all the attributes which are having high collinearity by taking threshold value to be above 0.81

cols=['radius_worst',
      'texture_worst',
      'perimeter_worst',
      'area_worst',
      'smoothness_worst',
      'compactness_worst',
      'concavity_worst',
      'concave points_worst',
      'symmetry_worst',
      'fractal_dimension_worst',
      'perimeter_mean',
      'perimeter_se',
      'area_mean',
      'area_se',
      'concavity_mean',
      'concavity_se',
      'concave points_mean',
      'concave points_se']
ip = ip.drop(cols, axis=1)

# Remaining columns after dropping the columns which has multi-collinearity
ip.columns

# Heatmap to visualize the collinearity after dropping the columns
corr = ip.corr().round(2)
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

f, ax = plt.subplots(figsize=(20, 20))
sns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5}, annot=True)
plt.tight_layout()

# Feature columns
X = ip.drop(['diagnosis'],axis=1)
X.head()

# Class labels
Y = ip.diagnosis
Y.head()

"""Scatter Plot Showing the data points between radius_mean and texture_mean"""

#scatter plot

X1 = X.iloc[:, :2]  # we only take the first two features.
y1 = Y

def make_meshgrid(x, y, h=.02):
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    return xx, yy

def plot_contours(ax, clf, xx, yy, **params):
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out

#giving hyperparameters in the SVM model

model = svm.SVC(kernel='rbf',C=1,gamma=0.1)
clf = model.fit(X1, y1)

fig, ax = plt.subplots()

# title for the plots
title = ('Decision surface of linear SVC ')

# Set-up grid for plotting.
X2, X3 = X1.iloc[:, 0], X1.iloc[:, 1]
xx, yy = make_meshgrid(X2, X3)

plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
ax.scatter(X2, X3, c=y1, cmap=plt.cm.coolwarm, s=20, edgecolors='k')
ax.set_ylabel('y label here')
ax.set_xlabel('x label here')
ax.set_xticks(())
ax.set_yticks(())
ax.set_title(title)
ax.legend()
plt.show()

"""After Splitting the data set into 70% and 30%, predicting the accuracy of dataset by fitting the dataset into SVM model"""

#Spliiting the data set into 70% training data and 30% test data

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=40)

print("Shape of training set:", X_train.shape)
print("Shape of test set:", X_test.shape)

#taking standardscaler to standardize the range of functionality of dataset
ss = StandardScaler()
X_train = ss.fit_transform(X_train)
X_test = ss.fit_transform(X_test)

# training the model on train set
model = SVC()
model.fit(X_train, Y_train)
 
# printing prediction results
predictions = model.predict(X_test)
print("Confusion Matrix: \n", confusion_matrix(Y_test, predictions))
print("\n")
print(classification_report(Y_test, predictions))
svm_acc = accuracy_score(Y_test, predictions)

#Printing training and test accuracies
print("Training accuracy of SVM model is:",(round(accuracy_score(Y_train, model.predict(X_train))*100,2)),"%")
print("Test Accuracy of SVM model is: ",(round(svm_acc*100,1)),"%")

"""The Accuracy of the dataset using SVM model is not accuracy unless we define HyperParameters C and gamma for SVM model, So Using GridSearchCV function importing from Sklearn Module we can find the values of C and gamma """

#Importing GridSearchCV function from sklearn
from sklearn.model_selection import GridSearchCV
 
# defining parameter range
param_grid = {'C': [0.1, 1, 10, 100, 1000],
              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
              'kernel': ['linear','rbf']}

#implementing GridSearchCV 
grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)
 
# fitting the model for grid search
grid.fit(X_train,Y_train)

# print best parameter after tuning
print(grid.best_params_)
 
# print how our model looks after hyper-parameter tuning
print(grid.best_estimator_)

"""After Finding the hyperparmeter values from GridSearc,giving the parameter values: Kernal,C and Gamma to give higher accuracy."""

#Taking standardscaler to standardize the range of functionality of dataset
ss = StandardScaler()
X_train = ss.fit_transform(X_train)
X_test = ss.fit_transform(X_test)

#Training the model with hyperparameters obtained from above gridsearch function
svc_model = SVC(kernel='rbf',C=1,gamma=0.1)
svc_model.fit(X_train, Y_train)

#Printing prediction results
predictions5 = svc_model.predict(X_test)
print("Confusion Matrix: \n", confusion_matrix(Y_test, predictions5))
print("\n")

#Printing classification Report
print(classification_report(Y_test, predictions5))
svm_acc = accuracy_score(Y_test, predictions5)

#Printing Training and Test accuracies
print("Training accuracy of SVM model is:",(round(accuracy_score(Y_train, svc_model.predict(X_train))*100,1)),"%")
print("Test Accuracy of SVM model is: ", (round(svm_acc*100,1)),"%")

y_pred_svm= svc_model.decision_function(X_test)

"""ROC Curve(Receiver Operating Characteristic curve) and AUC(Area Under the Curve) score shows the performance of the model at various threshold levels, higher the score hogher the model performance."""

#Graph for ROC curve and Calculating AUC Score importing from sklearn 
from sklearn.metrics import roc_curve,auc

svm_fpr,svm_tpr,threshold = roc_curve(Y_test,y_pred_svm)
auc_svm=auc(svm_fpr,svm_tpr)

#For Graph size
plt.figure(figsize=(5,5),dpi=100)
plt.plot(svm_fpr,svm_tpr,linestyle='-',label='SVM (auc=%0.3f)'%auc_svm)

#Taking x label and y label
plt.xlabel('False positive rate -->')
plt.ylabel('True Positive Rate-->')
plt.legend()
plt.show()

"""3-Fold Cross Validation for expermienting the dataset where the dataset is divided using the KFold function imported from sklearn module."""

#cross validation, importing kFold function from Sklearn
from sklearn.model_selection import KFold

#appending the SVM model 
models=[]
models.append(('SVM',SVC()))

#Taking 3 fold cross-validation
kf=KFold(n_splits=3)

#defining get_score function to fit the dataset with SVM model 
def get_score(model,X_train,X_test,Y_train,Y_test):
  model.fit(X_train,Y_train)
  return  model.score(X_train,Y_train)

#using for loop to get accuracies.
scores_SVM=[]
for train_index,test_index in kf.split(X):
  X_train, X_test = X.iloc[train_index], X.iloc[test_index]
  Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]
  scores_SVM.append(get_score(SVC(),X_train,X_test,Y_train,Y_test))
  
#printing average and 3 induvidual accuracies 
s=sum(scores_SVM)/len(scores_SVM)
print("Accuracy using 3-Fold Cross-Validation",round(s*100,1),"%")
scores_SVM

"""GridSearchCV function to generate the hyperparameter values for 3-Fold Cross Validation.Here, GridSearchCV function is imported from sklearn module.

---


"""

#Grid Search for considering hyperparameters for 3-fold cross validation 

best=[]
best1=[]
 
# defining parameter range
param_grid = {'C': [0.1, 1, 10, 100, 1000],
              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
              'kernel': ['linear','rbf']}
 
#defining get_score function to fit the dataset with SVM model 
def get_score(model,X_train,X_test,Y_train,Y_test):
  model.fit(X_train,Y_train)
  return  model.score(X_train,Y_train)

#using for loop to get accuracies.
scores_SVM=[]
for train_index,test_index in kf.split(X):
  X_train, X_test = X.iloc[train_index], X.iloc[test_index]
  Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]
  #using gridsearch 
  grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)
  grid.fit(X_train,Y_train)
  #appending parameter values 
  best.append(grid.best_estimator_)
  best1.append(grid.best_params_)
  
#Printing the parameters values  
print(best)
print(best1)

"""3-Fold Cross Validation after GridSearchCV function generating hyperparameter values and giving the hyperparameter values in SVC model which will give higher accuracy among the 3 generated hyperparameter values.

"""

#3-fold cross validation after grid search

def get_score(model,X_train,X_test,Y_train,Y_test):
  model.fit(X_train,Y_train)
  return  model.score(X_train,Y_train)

#using for loop to get accuracies.
scores_SVM=[]
for train_index,test_index in kf.split(X):
  X_train, X_test = X.iloc[train_index], X.iloc[test_index]
  Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]
  #appending accuracies into scores_SVM
  scores_SVM.append(get_score(SVC(kernel='linear',C=1000,gamma=1),X_train,X_test,Y_train,Y_test))
  
#printing average and 3 induvidual accuracies 
s=sum(scores_SVM)/len(scores_SVM)
print("Accuracy Using 3-Fold Cross-validation",round(s*100,1),"%")
scores_SVM